We have learned how to consume API's using request module. However, not every website has an API for us to work with. 
So in situation like that, the only way to get the data we want is to parse the html behind the we page get rid of all html tags, and extarct the actual data, this technique is called web scraping. So we scrape all the html tags and get the actual data we want. And that the things we are going to document here and we will do the project in a separate directory named - PyCrawler. 

I this project we are going to write a program in Python that will extract a list of questions on stackoverflow.com and we refer this kind of program as a web crawler or a web spider. Let's start...

1. Create a new project:
    a. Go to terminal and go to user: cd
    b. Make a derictory in user named pycrawler: mkdir pycrawler
    c. Then open the directory in VScode: code .

2. Install package and virtual environment:
    a. Install beautifulsoup: pipenv install beautifulsoup4
       This is a very popular python package to extract data from html and xml files.
    b. Install requests module: pipenv install requests
       We also need requests module to download the web page that contains the newest questions on stackoverflow.

3. Create py file:
    a. Create a py file: Let's say created crawler.py
    b. 